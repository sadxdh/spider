# Automatically created by: scrapy startproject
#
# For more information about the [deploy] section see:
# https://scrapyd.readthedocs.io/en/latest/deploy.html

# 改造成分布式爬虫步骤
# 1.导入scrapy_redis中的分布式爬虫类
# 2.继承类
# 3.注销 start_urls & allowed--domins
# 4.设置redis_key获取start_urls
# 5.设置__init__获取允许的域
#
# 6.copy配置参数
[settings]
default = douguo.settings

[deploy:douguowang] # 冒号后面写部署名
url = http://localhost:6800/
project = douguo
#部署： scrapyd-deploy douguowang（部署名） -p douguo（项目名）
#启动爬虫：curl http://localhost:6800/schedule.json -d project=default（项目名） -d spider=somespider（爬虫名称）

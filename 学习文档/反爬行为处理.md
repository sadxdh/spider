# 反爬行为处理

## 基于反爬行为的反爬

爬虫的行为与普通用户有非常明显的区别，爬虫的请求频率、请求次数要远高于普通用户

1. 通过请求ip/账号时间内总请求数量进行反爬
   1. 反爬原理：正常浏览器请求网站，速度不会太快，同一个ip/账号，大量请求了对方的服务器，更大的机率就会被识别为爬虫
   2. 解决方法：对应的购买大量的高质量ip伪装用户
2. 通过同一个ip/账号请求之间的间隔来进行反爬
   1. 反爬原理：正常人操作浏览器浏览网站，请求的时间间隔是随机的，而爬虫前后两个请求之间的时间间隔通常是固定的时间，时间间隔也很短
   2. 解决方法：请求之间进行随机等待，模拟真实用户的操作，在添加时间间隔后，为了能够快速获取数据，尽量使用代理池，如果是账号，在账号请求之间设置随机休眠
3. 同归哦对请求ip/账号每天设置阈值进行反爬
   1. 反爬原理：正常的浏览行为，一天的请求数量是有限的，通常超过某一个值，服务器就会拒绝响应
   2. 解决方法：对应的通过购买高质量的ip的方法、多账号，同时设置请求之间的随机休眠

## 根据爬虫操作进行反爬

1. 通过**js跳转**实现反爬

   1. 反爬原理：js实现页面跳转，无法在源码中获取到下一页的url
   2. 解决方法：多次抓包获取条状url，分析规律

2. 通过**蜜罐（陷阱）获取爬虫ip（或代理ip）**反爬

   1. 反爬原理：在爬虫获取链接进行请求的过程中，爬虫会根据正则，xapth，css等方式进行后续链接的提取，此时服务端可以设置一个陷阱url，会被提取规则获取，但正常用户无法获取，这样就可以区分爬虫和正常用户
   2. 解决方法：完成爬虫编写后，使用代理ip批量爬取测试/仔细分析响应内容结果，找出页面当中的蜜罐（陷进）

3. 通过假数据反爬

   1. 反爬原理：向返回的响应中添加假数据污染数据库，通常假数据不会被正常用户看到
   2. 解决方法：长期运行，核对数据库中数据同实际页面当中的数据情况，如果存在问题，仔细分析响应内容

4. 阻塞任务队列

   1. 反爬原理：通过生成大量的垃圾url，从而阻塞任务队列，降低爬虫的实际工作效率
   2. 解决方法：观察运行过程中请求响应状态/仔细分析源码获取垃圾url的生成规律，对url进行过滤

5. 阻塞网络IO

   1. 反爬原理：发送请求获取响应的实际过程就是下载的过程，在任务队列中混入一个大文件的url，当爬虫在进行请求时将会占用网络IO，如果是有多线程则会占用线程
   2. 解决方法：观察爬虫的运行状态/多线程对请求线程计时/发送请求栈

6. 运维平台综合审计

   1. 反爬原理：通过运维平台进行综合管理，通常采用复合型反爬虫策略，多种手段同时使用
   2. 解决方法：仔细观察分析，长期运行测试目标网站，检查数据采集速度，多方面进行处理

   